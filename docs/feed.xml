<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.0">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2023-02-04T14:46:26-05:00</updated><id>/feed.xml</id><title type="html">Sylvan Zheng</title><subtitle></subtitle><entry><title type="html">Delay</title><link href="/2023/02/04/timedelays-10.html" rel="alternate" type="text/html" title="Delay" /><published>2023-02-04T00:00:00-05:00</published><updated>2023-02-04T00:00:00-05:00</updated><id>/2023/02/04/timedelays-10</id><content type="html" xml:base="/2023/02/04/timedelays-10.html">&lt;p&gt;&lt;img src=&quot;https://nuum.co/wp-content/uploads/2022/01/opening-doctored.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The performer and her &lt;a href=&quot;https://nuum.co/project/doppelganger&quot;&gt;doppelganger&lt;/a&gt; stand still for a moment. She turns her head to the left. Her doppelganger follows suit. The doppelganger is the performer, but five seconds in the past.&lt;/p&gt;

&lt;p&gt;It’s cold today. Wind howls through the street. The farmer’s market is closed.&lt;/p&gt;

&lt;p&gt;A tech company starts sending more irrelevant notifications from its app to a random subset of its users. After a couple weeks, those users spend more time using the app compared to the others. The tech company rolls out the change to all of its users. A year later, I uninstall the app because the notifications are too annoying.&lt;/p&gt;

&lt;p&gt;The farmer’s market is closed today because twenty years ago there were too many chloroflourocarbons in the atmosphere.&lt;/p&gt;

&lt;p&gt;The doppelganger is the performer, but five minutes in the past. The performer turns her head to the right. The doppelganger is sitting in a chair, tying her shoes. Five minutes later, the doppelganger turns her head to the right. But I’ve already forgotten.&lt;/p&gt;</content><author><name></name></author><category term="writing" /><summary type="html"></summary></entry><entry><title type="html">Hot and Cold Media: Google Maps Edition</title><link href="/2023/02/03/maps-9.html" rel="alternate" type="text/html" title="Hot and Cold Media: Google Maps Edition" /><published>2023-02-03T00:00:00-05:00</published><updated>2023-02-03T00:00:00-05:00</updated><id>/2023/02/03/maps-9</id><content type="html" xml:base="/2023/02/03/maps-9.html">&lt;p&gt;When you’re using Google Maps navigation, the default perspective is first-person. The map is rotated and scaled to match your perspective as the driver/walker/biker: up is forward, down is backward, left and right both correspond to the real world left and right, assuming you’re holding your phone in its typical orientation. If you make a turn, the whole map rotates with you to maintain the correct first-person perspective.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://storage.googleapis.com/support-forums-api/attachment/thread-14375376-1383617846373138535.png&quot; width=&quot;256px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;The default Google Maps perspective&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;It’s really easy to see why this might be a good idea. Paper maps are normally oriented north-south, but most of the time when I’m trying to get from point A to point B I don’t care about whether I’m about to turn to the west - I just want to know if I need to go right or left. Paper maps don’t turn automatically, but I used to sometimes physically rotate maps to match the perspective I was seeing, a low-tech way of doing what Google maps navigation does automatically.&lt;/p&gt;

&lt;p&gt;Marshall Mcluhan might describe this as a “hot” map media experience. The media is “high definition,” a simulation of reality rather than a mere representation. Paper maps are most certainly “cold,” requiring its users to do a fair bit of mental work to translate what they’re seeing on the map to the physical, geospatial reality around them.&lt;/p&gt;

&lt;p&gt;I don’t miss having to page through an atlas to plan a road trip but I do think that there’s something that is lost when first person Google maps style navigation becomes the primary way used to navigate through place. I notice that I can almost never remember basic directions to routes I’ve driven dozens of times, and even if I might know that place A is 5 minutes away from place B and place C is 10 minutes away from place B, I have no idea where place A might be relative to place C. Google maps enables a kind of shitty teleportation, where I don’t have to pay any attention to my surroundings as I navigate them - I merely follow directions and get to where I’m going, thanks to how “hot” the map technology is (in Mcluhan’s sense of the word).&lt;/p&gt;

&lt;p&gt;It’s this kind of thing that makes stories of people following Google/Apple maps into a desert to the point of being stranded seem actually believable.&lt;/p&gt;

&lt;p&gt;You can force north-south orientation even during navigation by tapping the compass icon (at least at the time of this writing). This one weird trick™ already helps to recover some of the “coolness” of a paper map (pun intended). I notice very quickly if I’ve accidentally routed to the wrong place, since I have a vague sense of whether my destination is north/south/east/west of my current location. I can improvise shortcuts and detours around random construction or school buses. I have a sense of where different things are relative to each other, since I’m forced to constantly evaluate relative positions and directions as I navigate.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://storage.googleapis.com/support-forums-api/attachment/thread-2851431-14251814094790275470.png&quot; width=&quot;256px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;The north-south orientation navigation view&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Here’s to hoping that Google never kills this feature. “Cold” tech is a rare thing.&lt;/p&gt;</content><author><name></name></author><category term="writing" /><summary type="html">When you’re using Google Maps navigation, the default perspective is first-person. The map is rotated and scaled to match your perspective as the driver/walker/biker: up is forward, down is backward, left and right both correspond to the real world left and right, assuming you’re holding your phone in its typical orientation. If you make a turn, the whole map rotates with you to maintain the correct first-person perspective.</summary></entry><entry><title type="html">Validate your shit</title><link href="/2023/02/02/validation-8.html" rel="alternate" type="text/html" title="Validate your shit" /><published>2023-02-02T00:00:00-05:00</published><updated>2023-02-02T00:00:00-05:00</updated><id>/2023/02/02/validation-8</id><content type="html" xml:base="/2023/02/02/validation-8.html">&lt;p&gt;when reading paper or at talk with fancy scary machine learning or text analysis technique.&lt;/p&gt;

&lt;p&gt;think what is dumbest way. ask if fancy way really better.&lt;/p&gt;

&lt;p&gt;how understand differences in language usage? count how many word different no use embeddings or topic model.&lt;/p&gt;

&lt;p&gt;try predict which campaign ad persuasive with machine learning? guess probably no effect every time probably better.&lt;/p&gt;

&lt;p&gt;want know which tweet about politics? see if has word “democrats” or “republicans” in it. no build BERT transformer classifier.&lt;/p&gt;

&lt;p&gt;sometimes fancy way look good but only from certain angle like &lt;a href=&quot;https://grugbrain.dev/&quot;&gt;grug&lt;/a&gt; in mirror.&lt;/p&gt;</content><author><name></name></author><category term="writing" /><summary type="html">when reading paper or at talk with fancy scary machine learning or text analysis technique.</summary></entry><entry><title type="html">How many calves go into whey?</title><link href="/2023/02/01/whey-7.html" rel="alternate" type="text/html" title="How many calves go into whey?" /><published>2023-02-01T00:00:00-05:00</published><updated>2023-02-01T00:00:00-05:00</updated><id>/2023/02/01/whey-7</id><content type="html" xml:base="/2023/02/01/whey-7.html">&lt;p&gt;You could say I’m ve-curious.&lt;/p&gt;

&lt;p&gt;Question: how many calves need to be born in order to produce 1kg of whey protein powder?&lt;/p&gt;

&lt;p&gt;Answer: about 0.07! One pregnancy lasts for a year with the cow producing 8 gallons or 30L per day. That’s about 11KL per calf. Meanwhile, it takes 200L of milk to yield 1kg of whey protein, so each pregnancy yields about 15kg of whey protein (and about 25x as much casein).&lt;/p&gt;

&lt;p&gt;Apparently dairy cows also only give birth three times generally before being slaughtered for beef.&lt;/p&gt;

&lt;p&gt;This exercise is a little cold and morbid but I genuinely was curious what the environmental and (potential) moral cost of dairy/whey consumption was. In general it’s a lot lower than I expected, although I haven’t done THAT much work to double check the figures. It’s kind of insane that a dairy cow produces 11KL of milk over the course of a year during one pregnancy. That’s just an absurd quantity.&lt;/p&gt;

&lt;p&gt;From a cow life experience point of view, probably not awesome being milked 24/7 for three years in a row and then slaughtered.&lt;/p&gt;</content><author><name></name></author><category term="writing" /><summary type="html">You could say I’m ve-curious.</summary></entry><entry><title type="html">The art and aesthetics of (social) science</title><link href="/2023/01/31/aesthetics-6.html" rel="alternate" type="text/html" title="The art and aesthetics of (social) science" /><published>2023-01-31T00:00:00-05:00</published><updated>2023-01-31T00:00:00-05:00</updated><id>/2023/01/31/aesthetics-6</id><content type="html" xml:base="/2023/01/31/aesthetics-6.html">&lt;p&gt;Sometimes people are surprised that an artist (me) is in a rigorous social science PhD program. The common perception is that the type of thinking that artists do is aesthetic, emotional, subjective, whereas scientists in academia are more often engaged in objective, scientific, logical types of thinking.&lt;/p&gt;

&lt;p&gt;I actually find the two disciplines to share a surprising amount in common. The types of output are obviously very, very different visually and conceptually. But maybe surprisingly, aesthetic plays a huge role in modern social science, and a big part of a PhD program is actually learning to recognize and critique different aesthetic research traditions while also working to produce your own, hopefully aesthetically attractive creative work.&lt;/p&gt;

&lt;p&gt;The social scientist weaves together ideas about the world with some kind of observations from it, and presents a composite package that attempts to say something meaningful about a social process. Like traditional visual arts, there is very much an objective technical component (fluency with statistics, mastery of brush control), but neither art nor social science are judged purely on technical ability alone. Instead, a set of concerns that can be loosely described using the word “aesthetics” dominates.&lt;/p&gt;

&lt;p&gt;In political science and economics, &lt;em&gt;causal questions&lt;/em&gt; are all the rage - attempting to understand whether X causes Y (eg, does the type of government you have affect your country’s economy?)&lt;sup id=&quot;fnref:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;. The kicker with causal questions is that they are basically impossible to answer completely, because you can never compare the world with X to the world with not-X for the same person/country/state/etc. X either happened or it didn’t - we’ll never know really how the United States under a dictatorship would have turned out because we live in the timeline where it is a democracy&lt;sup id=&quot;fnref:2&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;. Not being able to observe the “counterfactual” is known as the ‘fundamental problem of causal inference’.&lt;/p&gt;

&lt;p&gt;Every attempt to answer a causal question is flawed. We get around the issue by making certain, untestable assumptions about the world and our observations - but each of these assumptions is an imperfection in the intellectual house of cards that makes up a research paper. The aesthetic question is whether the flaws are truly ugly, or merely acceptable, or in rare cases even elegant.&lt;/p&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Whether causal questions themselves are “beautiful” or important is also an aesthetic concern. &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;For now. &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name></name></author><category term="writing" /><summary type="html">Sometimes people are surprised that an artist (me) is in a rigorous social science PhD program. The common perception is that the type of thinking that artists do is aesthetic, emotional, subjective, whereas scientists in academia are more often engaged in objective, scientific, logical types of thinking.</summary></entry><entry><title type="html">Worse but cheaper</title><link href="/2023/01/27/worse-5.html" rel="alternate" type="text/html" title="Worse but cheaper" /><published>2023-01-27T00:00:00-05:00</published><updated>2023-01-27T00:00:00-05:00</updated><id>/2023/01/27/worse-5</id><content type="html" xml:base="/2023/01/27/worse-5.html">&lt;p&gt;Sometimes it’s possible to make something that exists (a product, service, etc) worse but significantly cheaper. In economics terms, this would be a marginal improvement to the extent that how much “worse” the thing becomes in dollars is less than how much money is saved by it becoming cheaper.&lt;/p&gt;

&lt;p&gt;In a diverse market with all kinds of services and products at different value points, this kind of price-point on its own isn’t necessarily a bad thing. Company A might offer a kinda bad service at dirt cheap prices while company B offers a pretty good service at a pretty expensive price. They might have similar “value” (maybe expressed by something like &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;quality - price&lt;/code&gt;).&lt;/p&gt;

&lt;p&gt;The problem is that if it becomes way easier to make small changes that dramatically move price while only moderately making quality worse. Assume it’s a no-brainer for company B to save 100M dollars and only sacrifice 1M in revenue from lessened customer experience. The market dictates that company B either makes that change, or dies.&lt;/p&gt;

&lt;p&gt;This results in a race to the bottom where everything sucks but approaches free in price.&lt;/p&gt;

&lt;p&gt;I think this is a decent model for a large part of the first world economy today, unfortunately. Software, is AMAZING at making an existing service way cheaper but a tiny bit worse, typically by using automation and conceptual abstraction to build scale at the cost of local detail.&lt;/p&gt;</content><author><name></name></author><category term="writing" /><summary type="html">Sometimes it’s possible to make something that exists (a product, service, etc) worse but significantly cheaper. In economics terms, this would be a marginal improvement to the extent that how much “worse” the thing becomes in dollars is less than how much money is saved by it becoming cheaper.</summary></entry><entry><title type="html">Working From Home Considered Harmful</title><link href="/2023/01/26/wfh-4.html" rel="alternate" type="text/html" title="Working From Home Considered Harmful" /><published>2023-01-26T00:00:00-05:00</published><updated>2023-01-26T00:00:00-05:00</updated><id>/2023/01/26/wfh-4</id><content type="html" xml:base="/2023/01/26/wfh-4.html">&lt;p&gt;Throughout the COVID pandemic I have felt mostly positive about the shift to remote work/work from home. Who doesn’t love the ability to get laundry or errands done in the middle of a work day? A spontaneous nap, an hour of commute saved? Even when it comes to actually working and not playing hooky there are undeniable benefits. I bought a standing desk, an Aeron chair, a 27” 4K monitor, ergo keyboard, and occasionally found myself deep in the zone cranking out code or research tasks while pumping music through a nice set of studio monitors. Developer heaven, for the most part.&lt;/p&gt;

&lt;p&gt;Now the pandemic is mostly over and I’ve been wrestling with the rather novel problem of building my own work and life routines from scratch. This is of course compounded by the fact that PhD programs are notoriously unstructured. I have an office on campus but it’s cramped, the 1080p monitor makes my eyes bleed, and there’s no natural light to speak of. Most of my research can be done anywhere with an internet connection, so why wouldn’t I work from the comfort of my home office the majority of the time?&lt;/p&gt;

&lt;p&gt;By chance, this semester’s class schedule forces a lot more time away from home (many same-day early morning and late afternoon classes). I’ve noticed my life feels qualitatively way better. A large amount of existential angst and anxiety has absolutely evaporated. While I wouldn’t be a good social scientist without noting that correlation doesn’t always equal causation, I’m fairly confident in a number of theoretical explanations for why working from home actually sucks. (After all, class schedules are arguably an exogenous shock to work-from-home exposure, no?)&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Mental separation between work and relaxation created by different physical space. This one is huge. I’m not sure if I’m wired more aggressively than others, but it feels so easy to waste time watching Youtube videos and surfing reddit in my home office compared to a coffee shop or my department office. Humans are incredibly spatially aware, and maintaining strong associations between activities and spaces has always been really helpful for me whenever I’ve noticed I’m having trouble spending time the way that I want to.&lt;sup id=&quot;fnref:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Spontaneous interactions. Nothing interesting happens at home - only exactly that which I expect to happen. At the department, I might attend a talk, have a hallway conversation with a professor. I might visit a bookstore on the way home. I might see a gallery opening poster on the walk to the subway. I engage with the world more wholly outside, than inside. This seems trivially obvious, but for a long time I somehow justified paying New York rent to… live inside a small box and (rarely) go outside???&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;So yeah I guess if you feel like your life is oddly stagnant and you are frequently wracked with anxiety about whether you are being as productive as you could be, having a hard time justifying relaxation, and feel disconnected from your work… go touch grass?&lt;/p&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Curiously, even if I don’t accomplish much in the way of work I notice that I’m much more relaxed and less ashamed of slacking off/recharge activities at home if I spend the day out. Something about the primitive brain - daytime outside, nighttime inside. &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name></name></author><category term="writing" /><summary type="html">Throughout the COVID pandemic I have felt mostly positive about the shift to remote work/work from home. Who doesn’t love the ability to get laundry or errands done in the middle of a work day? A spontaneous nap, an hour of commute saved? Even when it comes to actually working and not playing hooky there are undeniable benefits. I bought a standing desk, an Aeron chair, a 27” 4K monitor, ergo keyboard, and occasionally found myself deep in the zone cranking out code or research tasks while pumping music through a nice set of studio monitors. Developer heaven, for the most part.</summary></entry><entry><title type="html">idle time</title><link href="/2023/01/25/idle-time-3.html" rel="alternate" type="text/html" title="idle time" /><published>2023-01-25T00:00:00-05:00</published><updated>2023-01-25T00:00:00-05:00</updated><id>/2023/01/25/idle-time-3</id><content type="html" xml:base="/2023/01/25/idle-time-3.html">&lt;p&gt;&lt;a href=&quot;https://www.goodreads.com/book/show/42771901-how-to-do-nothing&quot;&gt;“How to Do Nothing: Resisting the Attention Economy”&lt;/a&gt; by Jenny Odell was probably one of the most annoying books I read in 2022.&lt;/p&gt;

&lt;p&gt;I wasn’t alone - a quick perusal of some of the more popular Goodreads reviews reveals some choice frustrations:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Odell has some interesting points but good lord does it seem like she would be exhausting to talk to at a party&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Woman discovers trees and then shares the experience in a language that the rest of us use to write grant proposals.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Collective self-help for middle-class leftist intelligentsia. Has the feeling of taking a leisurely stroll with your loony hippie friend who is at once an overeducated ecosocialist and a crackpot Zen mind-hacker. You have no idea why she loves birdwatching so much (to her it’s a proto-spiritual experience, to you it seems superficially like playing Pokémon Go) nor can you figure out how she affords to live on the Oakland-Piedmont border without a full-time job.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;It’s strange, because at the core the message of the book is something I actually resonate with fairly deeply. I feel exhausted by the constant pressure to be doing something else, something that might make me &lt;a href=&quot;https://www.youtube.com/watch?v=O4SzvsMFaek&quot;&gt;fitter, happier, more productive&lt;/a&gt; and it seems easy to point the finger at “the attention economy” and the constant comparison to more-successful others that social media usage can engender.&lt;/p&gt;

&lt;p&gt;For me one of the more frustrating features isn’t so much the obscure writing style or assumed privilege of her audience, but a lack of focus on actually understanding why it’s hard to do nothing now. A vague hand wave toward “capitalism” and “the attention economy” is as far as Odell gets. It’s less a book about how to do nothing but one about the myriad spiritual and moral benefits of doing nothing, and why doing nothing is good from different philosophical perspectives. It’s simultaneously didactic and yet doesn’t teach the reader much that is actually useful.&lt;/p&gt;

&lt;p&gt;Maybe the meta point is that if you want it to be useful you’re still in the clutches of trying to “do something” rather than “do nothing,” but it seriously comes off as lecturey at best and holier-than-thou at worst. The enlightened sermonize in the California sun while the damned scurry in the urban sewer.&lt;/p&gt;</content><author><name></name></author><category term="writing" /><summary type="html">“How to Do Nothing: Resisting the Attention Economy” by Jenny Odell was probably one of the most annoying books I read in 2022.</summary></entry><entry><title type="html">Creative Capital and Compound Interest</title><link href="/2023/01/24/compound-interest-2.html" rel="alternate" type="text/html" title="Creative Capital and Compound Interest" /><published>2023-01-24T00:00:00-05:00</published><updated>2023-01-24T00:00:00-05:00</updated><id>/2023/01/24/compound-interest-2</id><content type="html" xml:base="/2023/01/24/compound-interest-2.html">&lt;p&gt;When I got out of college I took a job at Facebook as a software engineer and mostly hated it (except for the part where I made way more money than any 23 year old has a right to). Privilege acknowledgements notwithstanding, this is a story that isn’t actually that unusual if you spend enough time on software forums like &lt;a href=&quot;https://news.ycombinator.com/item?id=21961560&quot;&gt;hackernews&lt;/a&gt; and reddit. A nontrivial amount of young people in tech (and possibly other industries!) wish they were doing something more creatively or intellectually fulfilling, whether that is social science research, experimental art, screenwriting, ceramics, whathaveyou. At least I was. But I got tempted by the astronomical signing bonus, starting salary, stock options, and the general allure of making a ton of cash as a young person right out of college, and I suspect many of my disenchanted peers fell prey to similar initial motivations.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.insider.com/53ac754b69bedda3512ad279?width=750&amp;amp;format=jpeg&amp;amp;auto=webp&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The temptation wasn’t material greed per se, but more security. One corner of the internet I discovered quickly was the &lt;a href=&quot;https://old.reddit.com/r/financialindependence/&quot;&gt;financial independence subreddit&lt;/a&gt;, which is full of people who meticulously save and invest money with the goal of eventually having enough to retire early and do whatever they want. A popular argument is that compound interest in the modern US stock market is so powerful and reliable that it is optimal to save as much as you can early, because that money will be worth twice, four times, eight times as much by the time one reaches retirement age. By the same logic, making more early on is also exponentially useful, and thus a decently large portion of the subreddit holds jobs they don’t love (or actively hate), holding out for one day getting to do what they actually want to do once they’ve saved up enough money for it.&lt;/p&gt;

&lt;p&gt;I spent a couple years checking my 401(k) several times per week and projecting out different savings timelines before I said fuck it, quit, and &lt;a href=&quot;/2021/06/11/itp.html&quot;&gt;went to art school&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Existential suffering aside, I think it’s important to realize that financial capital is not necessarily the most important type of capital you could be accumulating in your early career years. Creative capital is real too, and it also obeys the same laws of compound interest, even if it’s harder to see it. The more you learn and create, the more you can learn and create, and so on. If your actual end goal is to do something interesting with your time (and actually be good at it), it’s far from obvious that the correct path is to not do it so you can make money to do it later.&lt;/p&gt;</content><author><name></name></author><category term="writing" /><summary type="html">When I got out of college I took a job at Facebook as a software engineer and mostly hated it (except for the part where I made way more money than any 23 year old has a right to). Privilege acknowledgements notwithstanding, this is a story that isn’t actually that unusual if you spend enough time on software forums like hackernews and reddit. A nontrivial amount of young people in tech (and possibly other industries!) wish they were doing something more creatively or intellectually fulfilling, whether that is social science research, experimental art, screenwriting, ceramics, whathaveyou. At least I was. But I got tempted by the astronomical signing bonus, starting salary, stock options, and the general allure of making a ton of cash as a young person right out of college, and I suspect many of my disenchanted peers fell prey to similar initial motivations.</summary></entry><entry><title type="html">Web 2.1</title><link href="/2023/01/23/web-1.html" rel="alternate" type="text/html" title="Web 2.1" /><published>2023-01-23T00:00:00-05:00</published><updated>2023-01-23T00:00:00-05:00</updated><id>/2023/01/23/web-1</id><content type="html" xml:base="/2023/01/23/web-1.html">&lt;p&gt;Back in the 2000s “Web 2.0” was all the rage. The term heralded a different kind of internet. one where regular people were both the creators and the consumers. Putting content online used to be hard - the few produced, and the (relative) masses consumed. Web 2.0 removed technical barriers, promising a kind of democratization of content creation. Posting to the internet was born.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/foxtrot-web-21.png&quot; alt=&quot;&quot; /&gt;
&lt;a href=&quot;https://www.gocomics.com/foxtrot/2006/09/22&quot;&gt;FoxTrot on September 22, 2006, by Bill Amend&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;So when is web 2.1 due out? I’d argue we’ve already arrived. Ignore the crypto fanatics who are trying to claim “Web 3.0” for the decentralized web, and consider how Internet usage has changed since the 2000s. Craigslist, Facebook and MySpace, the leading lights of Web 2.0 feel like prehistoric dinosaurs. Instagram, Twitter, and TikTok dominate. Is it easy to post to these platforms? Technically speaking, yes. Anyone can post. You don’t need to know arcane computer programming skills in order to push content to the internet. But I think we’re missing something by just focusing on the technical details. People who push content to these platforms invest insane amounts of capital into producing content - and unlike early Web 2.0 projects, content on IG, Twitter, and TikTok is public by default. One competes with a global population of content creators who are probably better than you at it because it’s literally their job.&lt;/p&gt;

&lt;p&gt;The barrier to entry on early Facebook was low because you were competing with your friends. Most of the time, your friends were interested in what you had to say because you know, they were your friends. The barrier to entry on Twitter is high, because you are competing with Elon Musks’ latest controversy and the dozens-to-hundreds battle worn Twitter influencers who have already crafted a better incisive joke than you. Most people don’t actually care what you have to say.&lt;/p&gt;

&lt;p&gt;Naturally, what happens is that the pre-existing power law distribution of social networks is exacerbated. A select few people end up being specialized, professional content creators. A slightly larger population tries, mostly in vain, to break into internet stardom. The vast majority lurk.&lt;/p&gt;

&lt;p&gt;I call this influencer-centric model web 2.1. It’s Web 2.0 under the ruthless influence of the market. It’s sometimes good (influencers and content creators are usually more entertaining and interesting than my friends). It’s sometimes bad (influencers and content creators are usually more entertaining and interesting than my friends).&lt;/p&gt;

&lt;p&gt;This blog is an effort to combat the negative side. While there’s always some kind of pressure posting publicly to the internet I can at least pretend that it’s not being automatically entered into a cutthroat global attention competition. I don’t need my writing to compete in the global content marketplace, hell, there are probably six different authors on Substack that have already written more eloquently than I have or ever will on internet content economics. Fuck it though, I’ll post because I want to write and I need someplace to organize my thoughts and an easy way to share with my friends, who I hope, will be at least politely interested.&lt;/p&gt;</content><author><name></name></author><category term="writing" /><summary type="html">Back in the 2000s “Web 2.0” was all the rage. The term heralded a different kind of internet. one where regular people were both the creators and the consumers. Putting content online used to be hard - the few produced, and the (relative) masses consumed. Web 2.0 removed technical barriers, promising a kind of democratization of content creation. Posting to the internet was born.</summary></entry></feed>