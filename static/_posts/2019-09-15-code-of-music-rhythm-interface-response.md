---
layout: post
date: 2019-09-15
tags: itp code_of_music
title: Code of Music - Rhythm Interface Response
---

## Groove Pizza

[Groove Pizza](https://apps.musedlab.org/groovepizza/?source=pub&museid=SJnF-G2Lr&show-grid=true&multi-lock=&brainpop=false&midimap=&) uses a circular representation of the measure divided into a particular number of slices as the primary mechanism for representing rhythm. The user controls three voices - a kick, snare, and hi-hat sound and which of the measure subdivisions the voices "hit" on. Multi-measure rhythms are possible as well as control of swing, number of subdivisions (from one to sixteen).

- *Role of Sound*: This interface allows primarily for expressive / musical sound
- *Required Expertise*: This interface doesn't need any expertise necessarily to use it. The interface is intuitive and all features discoverable. Someone with no understanding of rhythm may take a little longer to fully understand all the parameters, but since the rhythms change in near real time it would be quick to learn that "tempo" refers to speed, "swing" refers to the offset-amount of every other beat, and so on.
- *Musical Control*: The user has roughly note-level control.
- *Degrees of Freedom*: The user only has control over the rhythm executed and there are some restrictions within that space. For instance, subdivisions are limited to maximum of 16, there only three voices that must play on the same grid, the rhythm will loop repeatedly without somewhat laborious intervention by the user.
- *Feedback Modalities*: There are two, visual and auditory. In particular I thought the visual effect of the swing parameter (seeing the grid points in the circle move slightly) was an effective way to communicate a relatively subtle musical idea.
- *Inter-cators*: Pretty much this interface is only for a single person to use, although different patterns can be shared between different users over the Internet.
- *Distribution in Space*: Strictly local

## Beat-Blender

[Beat Blender](https://experiments.withgoogle.com/ai/beat-blender/view/) represents rhythms using the traditional piano roll/grid notation. The interesting thing about Beat Blender is that it purports to use machine learning to be able to "blend" different rhythms together. The interface allows the user to explore the "space" generated by the machine learning algorithm between four different rhythms.
- *Role of Sound*: This interface also allows primarily for expressive / musical sound
- *Required Expertise*: This interface doesn't need any expertise necessarily to use it. The interface is intuitive and all features discoverable. Someone with a more advanced understanding of rhythm might be able to more quickly create interesting sequences, but like *Groove Pizza* the interface responds in real time with multiple modalities so it is relatively easy to learn.
- *Musical Control* / *Degrees of Freedom*: The user has roughly note-level control of the four corners, and can then choose where in the rhythm-space to explore afterward. The user has no control over timbral effects or the higher level process of how the rhythms are selected or generated.
- *Feedback Modalities*: There are two, visual and auditory.
- *Inter-cators*: Pretty much this interface is only for a single person to use, although different patterns can be shared between different users over the Internet.
- *Distribution in Space*: Strictly local
