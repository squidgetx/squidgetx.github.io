---
layout: post
date: 2020-02-10
tags: live_image itp
title: Video System (1/x)
---

This is the first post in a weekly series documenting my attempt at creating a performance system for an audiovisual piece that focuses on a few themes: digital alienation, sum of small parts, and audio-controlled visuals.

Essentially my plan is to write a piece of music for the guitar, use Max/MSP to analyze the timbre and prominent frequencies in real time and use this information to both transform audio processing effects and control visuals onscreen.

Here is a draft of some of the musical components I'm thinking about. It opens with a tremolo between dominant 7th intervals, a tense and anxious sound. The main chord progression struggles to find balance, cycling constantly between fifths never quite resolving. This harmonic aimlessness (I hope) aims to mirror the kind of internal imbalance brought on by the modern urban existence.
<audio controls>
  <source src="/docs/guitars.mp3" type="audio/mp3" />
  Your browser does not support the audio tag.
</audio>
I'm excited for the visual component of this project to underscore some of the themes in the music. Many times the inspration for the musical writing is abstract and hidden from the audience, but this will be an opportunity to allow for more specific mood-setting.

<iframe src="https://player.vimeo.com/video/390869413" width="640" height="480" frameborder="0" allow="autoplay; fullscreen" allowfullscreen></iframe>
<p><a href="https://vimeo.com/390869413">testoutput1</a> from <a href="https://vimeo.com/user59873575">Sylvan</a> on <a href="https://vimeo.com">Vimeo</a>.</p>

The current visual setup uses a random seek of a close up electronic screen texture luma-keyed to a high contrast clip of a fast moving crowd (pulled from *Koyaanaqatsi*). I'm hoping to add the ability to layer in at least one more video and then start working on the audio signal processing => image processing pipeline.

![](/images/lipp/hw1.png)
